{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_query_input():\n",
    "    '''\n",
    "    function takes no arguments\n",
    "    takes input from user and converts all characters to lower case \n",
    "    returns lower case string\n",
    "    '''\n",
    "    query = input(\"Enter you query : \")\n",
    "    return query.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def openindex_choice(choice):\n",
    "    '''\n",
    "    function takes 1 integer argument - choice\n",
    "    based on choice, loads a pre computed index of the form {term : {doc_id : term_frequency}} from a json file\n",
    "    returns the dictionary\n",
    "    '''\n",
    "    if(choice==1):\n",
    "        f=open('indt.json')\n",
    "        index=json.load(f)\n",
    "    else:\n",
    "        f=open('indwot.json')\n",
    "        index=json.load(f)\n",
    "    for word,string in index.items():\n",
    "        index[word]=json.loads(index[word])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openpostinglist_choice(choice):\n",
    "    '''\n",
    "    function takes 1 integer argument - choice\n",
    "    based on choice, loads a pre computed posting list of the form {doc_id : {term : term_frequency}} from a json file\n",
    "    returns the dictionary\n",
    "    '''\n",
    "    if(choice==1):\n",
    "        q=open('polt.json')\n",
    "        postinglist=json.load(q)\n",
    "    else:\n",
    "        q=open('polwot.json')\n",
    "        postinglist=json.load(q)\n",
    "    for docid,string in postinglist.items():\n",
    "        postinglist[docid]=json.loads(postinglist[docid])\n",
    "    return postinglist,len(postinglist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opentitle():\n",
    "    '''\n",
    "    function takes no arguments\n",
    "    loads a {doc_id: title} dictionary from a json file\n",
    "    returns the dictionary\n",
    "    '''\n",
    "    q=open('title.json')\n",
    "    title=json.load(q)\n",
    "    for docid,string in title.items():\n",
    "        title[docid]=list(json.loads(string).keys())[0].title()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "def correctquery(query):\n",
    "    '''\n",
    "    takes 1 string argument - query\n",
    "    returns the correctly spelled string\n",
    "    '''\n",
    "    spell=SpellChecker()\n",
    "    spell.distance=1\n",
    "    words=query.split(\" \")\n",
    "    corrected=[]\n",
    "    for word in words:\n",
    "        corrected.append(spell.correction(word))\n",
    "    return \" \".join(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_champion_list(r,index):\n",
    "    '''\n",
    "    takes 2 inputs - r and index\n",
    "    return a championlist for each word based on the term frequency \n",
    "    '''\n",
    "    champion_list={}\n",
    "    for word,word_index in index.items():\n",
    "        word_index_temp={k: v for k, v in sorted(word_index.items(), key=lambda item: item[1],reverse=True)}\n",
    "        count=r\n",
    "        champion_list[word]=[]\n",
    "        for docid in word_index_temp.keys():\n",
    "            if(count==0):\n",
    "                break\n",
    "            else:\n",
    "                champion_list[word].append(docid)\n",
    "                count=count-1\n",
    "    return champion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def form_query_vector(query,idf_values):\n",
    "    '''\n",
    "    takes 2 inputs - query(string) and idf_scores\n",
    "    it forms the query vector which is a dictionary of the format {word : norm(tfscore*idfscore)}\n",
    "    '''\n",
    "    query_tf={}\n",
    "    for w in query.strip().split(\" \"):\n",
    "        if(w in query_tf.keys()):\n",
    "            freq=query_tf[w];\n",
    "            query_tf[w]=freq+1;\n",
    "        else:\n",
    "            query_tf[w]=1;\n",
    "    query_vector={}\n",
    "    for key,value in query_tf.items():\n",
    "        if(key in idf_values.keys()):\n",
    "            query_vector[key]=(1+math.log(value,10))*(idf_values[key])\n",
    "        else:\n",
    "            query_vector[key]=(1+math.log(value,10))\n",
    "    query_norm_vector={}\n",
    "    values=query_vector.values();\n",
    "    values=[x*x for x in values]\n",
    "    for key,value in query_vector.items():\n",
    "        query_norm_vector[key]=(value/math.pow(sum(values),0.5))\n",
    "    return query_norm_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_idf_vector(index,no_of_docs):\n",
    "    '''\n",
    "    takes 2 inputs - index and no_of_docs\n",
    "    return idf_vector with idf_values of all words\n",
    "    '''\n",
    "    idf_values={}\n",
    "    for word,word_index in index.items():\n",
    "        length=len(index[word].keys())\n",
    "        idf_values[word]=math.log((no_of_docs/length),10)\n",
    "    return idf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_vector_for_a_word(word,index,doc_dict):\n",
    "    '''\n",
    "    takes 3 inputs - word,index,doc_dict\n",
    "    doc_dict contains the doc_vector for all docs(computed till the present moment)\n",
    "    doc_dict is of the form {doc_id : {word:norm(tfscore)}\n",
    "    it adds the word into the doc_vector of all docs who has the word present in it\n",
    "    '''\n",
    "    for docid,tf in index[word].items():\n",
    "        if(docid in doc_dict.keys()):\n",
    "            if(word not in doc_dict[docid].keys()):\n",
    "                doc_dict[docid][word]=1+math.log(tf,10)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            doc_dict[docid]={};\n",
    "            doc_dict[docid][word]=1+math.log(tf,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entire_doc_dict(query,index,posting_list):\n",
    "    '''\n",
    "    takes 3 inputs - query, index and posting_list\n",
    "    it builds the entire doc_dict for all the documents and returns it\n",
    "    '''\n",
    "    doc_dict={}\n",
    "    for w in query.strip().split(\" \"):\n",
    "        if(w in index.keys()):\n",
    "            build_doc_vector_for_a_word(w,index,doc_dict)\n",
    "        else:\n",
    "            pass\n",
    "    for docid in doc_dict.keys():\n",
    "        doc_vector=doc_dict[docid]\n",
    "        overlap=len(doc_vector.keys())\n",
    "        for word,tf in doc_vector.items():\n",
    "            doc_vector[word]=tf*overlap\n",
    "    for docid in doc_dict.keys():\n",
    "        posting_list_for_docid=posting_list[docid]\n",
    "        for word,tfscore in posting_list_for_docid.items():\n",
    "            if(word in doc_dict[docid].keys()):\n",
    "                pass\n",
    "            else:\n",
    "                doc_dict[docid][word]=1+math.log(tfscore,10);\n",
    "    for key,doc_vector in doc_dict.items():\n",
    "        values=doc_dict[key].values()\n",
    "        values=[x*x for x in values]\n",
    "        div=math.pow(sum(values),0.5)\n",
    "        for word,tfwt in doc_vector.items():\n",
    "            tfscore=doc_vector[word]\n",
    "            doc_vector[word]=tfscore/div\n",
    "    \n",
    "        \n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_vector_using_championlist(word,index,doc_dict,champion_list,posting_list):\n",
    "    '''\n",
    "    takes 5 inputs - word,index,doc_dict,champion_list,posting_list\n",
    "    doc_dict contains the doc_vector for all docs(computed till the present moment)\n",
    "    doc_dict is of the form {doc_id : {word:norm(tfscore)}\n",
    "    it adds the word into the doc_vector of only the docs which are present in the championlist\n",
    "    '''\n",
    "    for docid in champion_list[word] + list(doc_dict.keys()):\n",
    "        if(docid in doc_dict.keys()):\n",
    "            if((word not in doc_dict[docid].keys()) and (word in posting_list[docid].keys())):\n",
    "                doc_dict[docid][word]=1+math.log(index[word][docid],10)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            doc_dict[docid]={};\n",
    "            doc_dict[docid][word]=1+math.log(index[word][docid],10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_doc_vector_using_championlist(word,index,doc_dict,champion_list,posting_list):\n",
    "    '''\n",
    "    takes 5 inputs - word,index,doc_dict,champion_list,posting_list\n",
    "    it searches for the word present in docs which are present in doc_dict but not in the champion list\n",
    "    '''\n",
    "    for docid in list(doc_dict.keys()):\n",
    "        if(docid in doc_dict.keys()):\n",
    "            if((word not in doc_dict[docid].keys()) and (word in posting_list[docid].keys())):\n",
    "                doc_dict[docid][word]=1+math.log(index[word][docid],10)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            doc_dict[docid]={};\n",
    "            doc_dict[docid][word]=1+math.log(index[word][docid],10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entire_doc_dict_using_championlist(query,index,postinglist,champion_list):\n",
    "    '''\n",
    "    takes 4 inputs - query,index,postinglist,championlist\n",
    "    it returns the entire doc_dict built\n",
    "    '''\n",
    "    doc_dict={}\n",
    "    for w in query.strip().split(\" \"):\n",
    "        if(w in index.keys()):\n",
    "            build_doc_vector_using_championlist(w,index,doc_dict,champion_list,postinglist)\n",
    "        else:\n",
    "            pass\n",
    "    for w in query.strip().split(\" \"):\n",
    "        if(w in index.keys()):\n",
    "            complete_doc_vector_using_championlist(w,index,doc_dict,champion_list,postinglist)\n",
    "        else:\n",
    "            pass\n",
    "    for docid in doc_dict.keys():\n",
    "        doc_vector=doc_dict[docid]\n",
    "        overlap=len(doc_vector.keys())\n",
    "        for word,tf in doc_vector.items():\n",
    "            doc_vector[word]=tf*overlap\n",
    "    for docid in doc_dict.keys():\n",
    "        posting_list_for_docid=postinglist[docid]\n",
    "        for word,tfscore in posting_list_for_docid.items():\n",
    "            if(word in doc_dict[docid].keys()):\n",
    "                pass\n",
    "            else:\n",
    "                doc_dict[docid][word]=1+math.log(tfscore,10);\n",
    "    for key,doc_vector in doc_dict.items():\n",
    "        values=doc_dict[key].values()\n",
    "        values=[x*x for x in values]\n",
    "        div=math.pow(sum(values),0.5)\n",
    "        for word,tfwt in doc_vector.items():\n",
    "            tfscore=doc_vector[word]\n",
    "            doc_vector[word]=tfscore/div\n",
    "    \n",
    "        \n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entire_doc_dict_using_championlist_choice(query,index,postinglist,champion_list,choice):\n",
    "    '''\n",
    "    it takes 5 inputs - query,index,postinglist,champion_list,choice\n",
    "    and decides to build the entire dict based on the choice\n",
    "    choice==1 with championlist\n",
    "    choice==0 without championlist\n",
    "    '''\n",
    "    doc_dict={}\n",
    "    for w in query.strip().split(\" \"):\n",
    "        if(w in index.keys()):\n",
    "            build_doc_vector_using_championlist(w,index,doc_dict,champion_list,postinglist)\n",
    "        else:\n",
    "            pass\n",
    "    for w in query.strip().split(\" \"):\n",
    "        if(w in index.keys()):\n",
    "            complete_doc_vector_using_championlist(w,index,doc_dict,champion_list,postinglist)\n",
    "        else:\n",
    "            pass\n",
    "    if(choice==1):\n",
    "        for docid in doc_dict.keys():\n",
    "            doc_vector=doc_dict[docid]\n",
    "            overlap=len(doc_vector.keys())\n",
    "            for word,tf in doc_vector.items():\n",
    "                doc_vector[word]=tf*overlap\n",
    "    else:\n",
    "        pass\n",
    "    for docid in doc_dict.keys():\n",
    "        posting_list_for_docid=postinglist[docid]\n",
    "        for word,tfscore in posting_list_for_docid.items():\n",
    "            if(word in doc_dict[docid].keys()):\n",
    "                pass\n",
    "            else:\n",
    "                doc_dict[docid][word]=1+math.log(tfscore,10);\n",
    "    for key,doc_vector in doc_dict.items():\n",
    "        values=doc_dict[key].values()\n",
    "        values=[x*x for x in values]\n",
    "        div=math.pow(sum(values),0.5)\n",
    "        for word,tfwt in doc_vector.items():\n",
    "            tfscore=doc_vector[word]\n",
    "            doc_vector[word]=tfscore/div\n",
    "    \n",
    "        \n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_for_a_document(docid,doc_dict_for_docid,query_vector,doc_ranking):\n",
    "    '''\n",
    "    it takes 4 inputs - docid,document_vector,query_vector,doc_ranking\n",
    "    it computes the score between query_vector and doc_vector and adds it into the doc_ranking dictionary\n",
    "    doc_ranking dictionary is of the type {docid : score}\n",
    "    '''\n",
    "    rank_score=0\n",
    "    for word,score in query_vector.items():\n",
    "        if(word in doc_dict_for_docid.keys()):\n",
    "            rank_score+=(score)*(doc_dict_for_docid[word])\n",
    "        else:\n",
    "            pass\n",
    "    doc_ranking[docid]=rank_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def calculate_all(k):\n",
    "    '''\n",
    "    This is the python shell implementation of our function(kind of like the main function)\n",
    "    It takes the k value which takes as to how many documents you want to see\n",
    "    It will ask the user for a count which gives the user the choice to examine our IR model using various modifications\n",
    "    count=1 implements all the modifications simultaneously\n",
    "    count=2,3,4 implements the modifications individually so that you can examine the differnce\n",
    "    '''\n",
    "    count=input(\"1:Examine normal IR(with all modifications)\\n2:Examine championlist modification\\n3:Examine title term modification\\n4:Examine query overlap modification\\n\")\n",
    "    query=take_query_input()\n",
    "    query=correctquery(query)\n",
    "    if(int(count) != 3):\n",
    "        index=openindex_choice(1)\n",
    "        title=opentitle()\n",
    "        posting_list,no_of_docs=openpostinglist_choice(1)\n",
    "    else:\n",
    "        index=openindex_choice(1)\n",
    "        title=opentitle()\n",
    "        posting_list,no_of_docs=openpostinglist_choice(1)\n",
    "        index0=openindex_choice(0)\n",
    "        posting_list0,no_of_docs1=openpostinglist_choice(0)\n",
    "    champion_list=build_champion_list(10,index)\n",
    "    idf_values=build_idf_vector(index,no_of_docs)\n",
    "    query_vector=form_query_vector(query,idf_values)\n",
    "    #print(query_vector)\n",
    "    begin=time.time()\n",
    "    if(int(count)==1):\n",
    "        doc_dict1=build_entire_doc_dict_using_championlist(query,index,posting_list,champion_list)\n",
    "        end1=time.time()\n",
    "    elif(int(count)==2):\n",
    "        doc_dict1=build_entire_doc_dict_using_championlist(query,index,posting_list,champion_list)\n",
    "        end1=time.time()\n",
    "        doc_dict2=build_entire_doc_dict(query,index,posting_list)\n",
    "        end=time.time()\n",
    "    elif(int(count)==3):\n",
    "        doc_dict1=build_entire_doc_dict_using_championlist(query,index,posting_list,champion_list)\n",
    "        end1=time.time()\n",
    "        doc_dict2=build_entire_doc_dict_using_championlist(query,index0,posting_list0,champion_list)\n",
    "        end=time.time()\n",
    "    else:\n",
    "        doc_dict1=build_entire_doc_dict_using_championlist_choice(query,index,posting_list,champion_list,1)\n",
    "        end1=time.time()\n",
    "        doc_dict2=build_entire_doc_dict_using_championlist_choice(query,index,posting_list,champion_list,0)\n",
    "        end=time.time()\n",
    "    \n",
    "    doc_ranking1={}\n",
    "    for docid,docid_vector in doc_dict1.items():\n",
    "        calculate_score_for_a_document(docid,docid_vector,query_vector,doc_ranking1)\n",
    "    doc_ranking1={k: v for k, v in sorted(doc_ranking1.items(), key=lambda item: item[1],reverse=True)}\n",
    "    if(k>len(doc_ranking1.keys())):\n",
    "        k=len(doc_ranking1.keys())\n",
    "    first_k=list(doc_ranking1.keys())[0:k]\n",
    "    df=pd.DataFrame(columns=[['DOCID','Title','Score']])\n",
    "    for key in first_k:\n",
    "        df.loc[len(df.index)]=[key,title[key],doc_ranking1[key]]\n",
    "    print(\"-----------------\")\n",
    "    print(df)\n",
    "    print(\"-----------------\")\n",
    "    print(end1-begin)\n",
    "    \n",
    "    if(int(count)!=1):\n",
    "        doc_ranking2={}\n",
    "        for docid,docid_vector in doc_dict2.items():\n",
    "            calculate_score_for_a_document(docid,docid_vector,query_vector,doc_ranking2)\n",
    "        doc_ranking2={k: v for k, v in sorted(doc_ranking2.items(), key=lambda item: item[1],reverse=True)}\n",
    "        if(k>len(doc_ranking2.keys())):\n",
    "            k=len(doc_ranking2.keys())\n",
    "        first_k=list(doc_ranking2.keys())[0:k]\n",
    "        df1=pd.DataFrame(columns=[['DOCID','Title','Score']])\n",
    "        for key in first_k:\n",
    "            df1.loc[len(df1.index)]=[key,title[key],doc_ranking2[key]]\n",
    "        print(\"-----------------\")\n",
    "        print(df1)\n",
    "        print(\"-----------------\")\n",
    "        print(end-end1)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Examine normal IR(with all modifications)\n",
      "2:Examine championlist modification\n",
      "3:Examine title term modification\n",
      "4:Examine query overlap modification\n",
      "1\n",
      "Enter you query : Hello Paul\n",
      "-----------------\n",
      "      DOCID                                              Title     Score\n",
      "0  51149587                     Paul Townsend (Disambiguation)  0.229736\n",
      "1  51138661                               Paul Slane (Cyclist)  0.198746\n",
      "2  51160635                                Hello Kimberly Tour  0.190369\n",
      "3  51129397  We Want Our Daddy Dear, Back Home (Hello Centr...  0.171035\n",
      "4  51172913                                          Paul Augé  0.170823\n",
      "5  51181066                                       Maria Makino  0.140529\n",
      "6  51181183                                         Akane Haga  0.123714\n",
      "7  51133265                    Paul Gallagher (Trade Unionist)  0.106238\n",
      "8  51155104  Carl Reiner And Mel Brooks At The Cannes Film ...  0.086502\n",
      "9  51176631                             Paul Weir (Basketball)  0.086348\n",
      "-----------------\n",
      "0.0039904117584228516\n"
     ]
    }
   ],
   "source": [
    "calculate_all(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Basic IR System with all modifications\n",
    "####      Query : CEO of brandyourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Examine normal IR(with all modifications)\n",
      "2:Examine championlist modification\n",
      "3:Examine title term modification\n",
      "4:Examine query overlap modification\n",
      "1\n",
      "Enter you query : Ceo of brandyourself\n",
      "-----------------\n",
      "      DOCID                                 Title     Score\n",
      "0  51168474                        Patrick Ambron  0.334853\n",
      "1  51135825  Australian Foundation For Disability  0.113395\n",
      "2  51161862                        Diane Karusisi  0.101936\n",
      "3  51153753                        Kelly Murumets  0.098057\n",
      "4  51177161       Fort Bragg Federal Credit Union  0.095585\n",
      "5  51130761                          Punit Renjen  0.073755\n",
      "6  51129304                            Rr Auction  0.070688\n",
      "7  51176883                            Don Slager  0.068495\n",
      "8  51188774          New Entrepreneurs Foundation  0.066059\n",
      "9  51130430        John J. Mcgrath (Entrepreneur)  0.064669\n",
      "-----------------\n",
      "0.010970830917358398\n"
     ]
    }
   ],
   "source": [
    "calculate_all(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Examining the champion list modification\n",
    "####     Query : Potter first album in 1997 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Examine normal IR(with all modifications)\n",
      "2:Examine championlist modification\n",
      "3:Examine title term modification\n",
      "4:Examine query overlap modification\n",
      "2\n",
      "Enter you query : Potter first album in 1997\n",
      "-----------------\n",
      "      DOCID                                              Title     Score\n",
      "0  51190117                                   Catherine Potter  0.538644\n",
      "1  51178109                                         Lisa Haley  0.275269\n",
      "2  51155926                          Warner Bros. Studio Tours  0.268574\n",
      "3  51150018                              Telemedicine Act 1997  0.231708\n",
      "4  51149963                           Computer Crimes Act 1997  0.227113\n",
      "5  51143603                     Generation Y (Kunto Aji Album)  0.223151\n",
      "6  51149749                         Digital Signature Act 1997  0.217320\n",
      "7  51134795                                  Ugadi (1997 Film)  0.212734\n",
      "8  51154548  Warner Bros. Studio Tour London - The Making O...  0.203773\n",
      "9  51170136                                     Kodama (Album)  0.192428\n",
      "-----------------\n",
      "0.009973526000976562\n",
      "-----------------\n",
      "      DOCID                                  Title     Score\n",
      "0  51190117                       Catherine Potter  0.538644\n",
      "1  51134626                    Hand Of Fate (Song)  0.362388\n",
      "2  51168242        Loving You (Shirley Horn Album)  0.310218\n",
      "3  51141536                     Viduslaiki (Album)  0.306447\n",
      "4  51165157                    The Dolphin (Album)  0.284820\n",
      "5  51131224  Simplicity (The Bouncing Souls Album)  0.283550\n",
      "6  51156740          The Best (Edmond Leung Album)  0.279129\n",
      "7  51168442          It'S Alive (Buckethead Album)  0.275920\n",
      "8  51178109                             Lisa Haley  0.275269\n",
      "9  51155926              Warner Bros. Studio Tours  0.268574\n",
      "-----------------\n",
      "0.4073019027709961\n"
     ]
    }
   ],
   "source": [
    "calculate_all(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Examining the Title term modification\n",
    "####     Query : Diverse architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Examine normal IR(with all modifications)\n",
      "2:Examine championlist modification\n",
      "3:Examine title term modification\n",
      "4:Examine query overlap modification\n",
      "3\n",
      "Enter you query : Diverse architecture\n",
      "-----------------\n",
      "      DOCID                                              Title     Score\n",
      "0  51137214  Spectrum-Diverse Unified Neuroevolution Archit...  0.126060\n",
      "1  51131447                                      St Rose Music  0.118857\n",
      "2  51158012                              Vasthuvidya Gurukulam  0.084558\n",
      "3  51145584                                         Soho Radio  0.068928\n",
      "4  51129395                       Maltese Baroque Architecture  0.067579\n",
      "5  51183221               Webster County Courthouse (Nebraska)  0.063359\n",
      "6  51184343                                  Knowledge Inertia  0.062729\n",
      "7  51134202                                     Dolors Lamarca  0.057465\n",
      "8  51135958           Waterville Main Street Historic District  0.050998\n",
      "9  51138023                                    Elsa Law Review  0.049461\n",
      "-----------------\n",
      "0.004964590072631836\n",
      "-----------------\n",
      "      DOCID                                              Title     Score\n",
      "0  51131447                                      St Rose Music  0.133099\n",
      "1  51158012                              Vasthuvidya Gurukulam  0.085460\n",
      "2  51137214  Spectrum-Diverse Unified Neuroevolution Archit...  0.082629\n",
      "3  51145584                                         Soho Radio  0.070085\n",
      "4  51183221               Webster County Courthouse (Nebraska)  0.064402\n",
      "5  51184343                                  Knowledge Inertia  0.062872\n",
      "6  51129395                       Maltese Baroque Architecture  0.060161\n",
      "7  51134202                                     Dolors Lamarca  0.058268\n",
      "8  51135958           Waterville Main Street Historic District  0.051801\n",
      "9  51138023                                    Elsa Law Review  0.049819\n",
      "-----------------\n",
      "0.005012035369873047\n"
     ]
    }
   ],
   "source": [
    "calculate_all(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Examining the query overlap modification\n",
    "####     Query: dutch-born politician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:Examine normal IR(with all modifications)\n",
      "2:Examine championlist modification\n",
      "3:Examine title term modification\n",
      "4:Examine query overlap modification\n",
      "4\n",
      "Enter you query : dutch-born politician\n",
      "-----------------\n",
      "      DOCID                               Title     Score\n",
      "0  51128943         Paul Zimmerman (Politician)  0.167927\n",
      "1  51171957       Harold Armstrong (Politician)  0.146833\n",
      "2  51172884            Harry Innes (Politician)  0.132314\n",
      "3  51137297         John Bridgeman (Politician)  0.102142\n",
      "4  51145357         Fred M. Wilcox (Politician)  0.099372\n",
      "5  51129249             Don Barker (Politician)  0.067302\n",
      "6  51157716       Mercedes Alvarez (Politician)  0.065830\n",
      "7  51170479      Richard G. Austin (Politician)  0.061770\n",
      "8  51131935          Mehmet Yıldız (Politician)  0.057904\n",
      "9  51135046  John Bailey (Victorian Politician)  0.050349\n",
      "-----------------\n",
      "0.0009646415710449219\n",
      "-----------------\n",
      "      DOCID                               Title     Score\n",
      "0  51171957       Harold Armstrong (Politician)  0.146833\n",
      "1  51172884            Harry Innes (Politician)  0.132314\n",
      "2  51137297         John Bridgeman (Politician)  0.102142\n",
      "3  51145357         Fred M. Wilcox (Politician)  0.099372\n",
      "4  51128943         Paul Zimmerman (Politician)  0.085582\n",
      "5  51129249             Don Barker (Politician)  0.067302\n",
      "6  51157716       Mercedes Alvarez (Politician)  0.065830\n",
      "7  51170479      Richard G. Austin (Politician)  0.061770\n",
      "8  51131935          Mehmet Yıldız (Politician)  0.057904\n",
      "9  51135046  John Bailey (Victorian Politician)  0.050349\n",
      "-----------------\n",
      "0.0010309219360351562\n"
     ]
    }
   ],
   "source": [
    "calculate_all(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
